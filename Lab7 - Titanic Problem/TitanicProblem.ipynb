{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading data from kaggle"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntrain_data= pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":299,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Filtering data:\nI want to sort and split to tables by missing values to get different set's to learn.\nI choose to use columns: Pclass, Sex, Age, Embarked and Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"fcols = {\n    \"Age\":[],\n    \"Cabin\":[],\n    \"Embarked\":[]\n}\nfTcols = {\n    \"Age\":[],\n    \"Cabin\":[],\n    \"Embarked\":[]\n}\nfor key in fcols.keys():\n    fcols[key] = pd.notnull(train_data[key])\n    fTcols[key] = pd.notnull(test_data[key])\n    \ntrainFiltered = [\n    train_data[np.logical_and(fcols[\"Age\"],fcols[\"Cabin\"])],\n    train_data[np.logical_and(fcols[\"Cabin\"],fcols[\"Embarked\"])],\n    train_data[np.logical_and(fcols[\"Age\"],fcols[\"Embarked\"])],\n    train_data[np.logical_and(np.logical_and(fcols[\"Age\"],fcols[\"Cabin\"]),fcols[\"Embarked\"])]\n]\ntrainTestFiltered = [\n    test_data[np.logical_and(fTcols[\"Age\"],fTcols[\"Cabin\"])],\n    test_data[np.logical_and(fTcols[\"Cabin\"],fTcols[\"Embarked\"])],\n    test_data[np.logical_and(fTcols[\"Age\"],fTcols[\"Embarked\"])],\n    test_data[np.logical_and(np.logical_and(fTcols[\"Age\"],fTcols[\"Cabin\"]),fTcols[\"Embarked\"])]\n]","execution_count":301,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generating Predictions\nFor each filtered earlier group + Class, Sex tags, I generate different model to predict. Creating more accurate groups allows the tree to be deepened."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nohe=OneHotEncoder(handle_unknown='ignore')\n\ndataSets = [[\"Pclass\",\"Sex\",\"Age\",\"Cabin\"],[\"Pclass\",\"Sex\",\"Cabin\",\"Embarked\"],[\"Pclass\",\"Sex\",\"Age\",\"Embarked\"],[\"Pclass\",\"Sex\",\"Age\",\"Cabin\",\"Embarked\"]]\n\nresultData = [pd.DataFrame({'PassengerId': train_data[\"PassengerId\"], 'Survived': 0})]\nresultTestData = [pd.DataFrame({'PassengerId': test_data[\"PassengerId\"], 'Survived': 0})]\n\nfor i, dataSet in enumerate(dataSets):\n    y = trainFiltered[i][\"Survived\"]\n    \n    X = ohe.fit_transform(trainFiltered[i][dataSet])\n    X_test = ohe.transform(trainTestFiltered[i][dataSet])\n    \n    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\n    model.fit(X, y)\n    \n    resultData.insert(i, pd.DataFrame({'PassengerId': trainFiltered[i][\"PassengerId\"], 'Survived': model.predict(X)}))\n    resultData[i].loc[resultData[i]['Survived'] == 0, 'Survived'] = -1\n    print(\"Filter accuracy:\",accuracy_score(y, model.predict(X)))\n    model.predict(X_test)\n    resultTestData.insert(i, pd.DataFrame({'PassengerId': trainTestFiltered[i][\"PassengerId\"], 'Survived': model.predict(X_test)}))\n    resultTestData[i].loc[resultTestData[i]['Survived'] == 0, 'Survived'] = -1\n    ","execution_count":302,"outputs":[{"output_type":"stream","text":"Filter accuracy: 0.9513513513513514\nFilter accuracy: 0.9207920792079208\nFilter accuracy: 0.848314606741573\nFilter accuracy: 0.9617486338797814\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Final Result\nMerging and summing predictions from all filters, the resultant sum is the probability of surviving."},{"metadata":{"trusted":true},"cell_type":"code","source":"finalResult = pd.concat(resultData).groupby(['PassengerId'],as_index=False)['Survived'].sum()\nfinalResult.loc[finalResult['Survived'] < 0, 'Survived'] = 0\nfinalResult.loc[finalResult['Survived'] > 0, 'Survived'] = 1\nprint(\"Train data accuracy:\",accuracy_score(train_data[\"Survived\"], finalResult[\"Survived\"]))\n\nresultTestData = pd.concat(resultTestData).groupby(['PassengerId'],as_index=False)['Survived'].sum()\nresultTestData.loc[resultTestData['Survived'] < 0, 'Survived'] = 0\nresultTestData.loc[resultTestData['Survived'] > 0, 'Survived'] = 1\n\nresultTestData.to_csv('my_submission.csv', index=False)\nprint(\"Saved\")","execution_count":303,"outputs":[{"output_type":"stream","text":"Train data accuracy: 0.8597081930415263\nSaved\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Summary\nOverall accuracy of this code is scored at 0.76794 which means, I predicted third part of the passengers that were alive after catastrophe.\nSplitting data before training improved this algorithm by 0.04. I don't think that's ideal way to solve this, but for less important predictions it is enough."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}